{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nlp516\n",
    "import nlp516.model\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from types import SimpleNamespace\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = nlp516.data.PublicTrialRaw()\n",
    "raw = nlp516.data.PublicEnglishDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_map = nlp516.data.Tokenizer('english')\n",
    "stopwords_map = nlp516.data.RemoveStopWords('english')\n",
    "stemmer_map = nlp516.data.Stemmer('english')\n",
    "\n",
    "def preprocess(dataset):\n",
    "    def run(data):\n",
    "        data = nlp516.data.map_column(data, 'text', nlp516.data.remove_urls_map)\n",
    "        #en = nlp516.data.map_column(dataset.en, 'text', nlp516.data.casual_tokenize_map)\n",
    "        data = nlp516.data.map_column(data, 'text', tokenizer_map)\n",
    "        #data = nlp516.data.map_column(data, 'text', nlp516.data.user_camelcase_map)\n",
    "        data = nlp516.data.map_column(data, 'text', nlp516.data.hashtag_camelcase_map)\n",
    "        data = nlp516.data.map_column(data, 'text', nlp516.data.to_lowercase)\n",
    "        data = nlp516.data.map_column(data, 'text', stopwords_map)\n",
    "        data = nlp516.data.map_column(data, 'text', stemmer_map)\n",
    "        data = nlp516.data.map_column(data, 'text', nlp516.data.remove_words_with_numbers)\n",
    "        return data\n",
    "    return SimpleNamespace(train = run(dataset.train),\n",
    "                           valid = run(dataset.valid))\n",
    "dataset = preprocess(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original: {}'.format(dataset.train.iloc[25].text))\n",
    "print('Tokens: {}'.format(raw.train.iloc[25].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original: {}'.format(dataset.train.iloc[1].text))\n",
    "print('Tokens: {}'.format(raw.train.iloc[1].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original: {}'.format(dataset.train.iloc[26].text))\n",
    "print('Tokens: {}'.format(raw.train.iloc[26].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def random_shuffle(data):\n",
    "#    idx = np.arange(en.shape[0])\n",
    "#    shuffle = np.random.shuffle(idx)\n",
    "#    return data.iloc[idx, :]\n",
    "#dataset = random_shuffle(en)\n",
    "train = dataset.train\n",
    "test = dataset.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nlp516.model.MlModel(80)\n",
    "model.fit(train.text, train.HS)\n",
    "print('test: {}'.format(model.score(test.text, test.HS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nlp516.model.MlModel(50)\n",
    "model.fit(train.text, train.TR)\n",
    "print('test: {}'.format(model.score(test.text, test.TR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nlp516.model.MlModel(50)\n",
    "model.fit(train.text, train.AG)\n",
    "print('test: {}'.format(model.score(test.text, test.AG)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[model.vectorizer.id2word(id) for id in model.vectorizer.feature_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-test.HS.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-test.AG.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
