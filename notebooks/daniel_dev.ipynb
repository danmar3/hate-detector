{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nlp516\n",
    "import nlp516.model\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from types import SimpleNamespace\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = nlp516.data.PublicTrialRaw()\n",
    "language = 'english'\n",
    "if language == 'spanish':\n",
    "    raw = nlp516.data.PublicSpanishDataset()\n",
    "elif language=='english':\n",
    "    raw = nlp516.data.PublicEnglishDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_map = nlp516.data.Tokenizer('english')\n",
    "stopwords_map = nlp516.data.RemoveStopWords(language)\n",
    "stemmer_map = nlp516.data.Stemmer(language)\n",
    "\n",
    "def preprocess(dataset):\n",
    "    def run(data):\n",
    "        data = nlp516.data.map_column(data, 'text', nlp516.data.remove_urls_map)\n",
    "        #en = nlp516.data.map_column(dataset.en, 'text', nlp516.data.casual_tokenize_map)\n",
    "        data = nlp516.data.map_column(data, 'text', tokenizer_map)\n",
    "        data = nlp516.data.map_column(data, 'text', nlp516.data.user_camelcase_map)\n",
    "        data = nlp516.data.map_column(data, 'text', nlp516.data.hashtag_camelcase_map)\n",
    "        data = nlp516.data.map_column(data, 'text', nlp516.data.to_lowercase)\n",
    "        data = nlp516.data.map_column(data, 'text', stopwords_map)\n",
    "        #data = nlp516.data.map_column(data, 'text', stemmer_map)\n",
    "        data = nlp516.data.map_column(data, 'text', nlp516.data.remove_words_with_numbers)\n",
    "        data = nlp516.data.map_column(data, 'text', nlp516.data.remove_punctuation)\n",
    "        return data\n",
    "    return SimpleNamespace(train = run(dataset.train),\n",
    "                           valid = run(dataset.valid))\n",
    "dataset = preprocess(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original: {}'.format(raw.train.iloc[25].text))\n",
    "print('Tokens: {}'.format(dataset.train.iloc[25].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original: {}'.format(raw.train.iloc[1].text))\n",
    "print('Tokens: {}'.format(dataset.train.iloc[1].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original: {}'.format(raw.train.iloc[26].text))\n",
    "print('Tokens: {}'.format(dataset.train.iloc[26].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def random_shuffle(data):\n",
    "#    idx = np.arange(en.shape[0])\n",
    "#    shuffle = np.random.shuffle(idx)\n",
    "#    return data.iloc[idx, :]\n",
    "#dataset = random_shuffle(en)\n",
    "train = dataset.train\n",
    "test = dataset.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nlp516.model.SVMModel(100)\n",
    "model.fit(dataset.train.text, dataset.train.HS)\n",
    "print('test: {}'.format(model.score(dataset.valid.text, dataset.valid.HS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nlp516.model.SVMModel(100)\n",
    "model.fit(dataset.train.text, train.TR)\n",
    "print('test: {}'.format(model.score(dataset.valid.text, dataset.valid.TR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nlp516.model.SVMModel(100)\n",
    "model.fit(dataset.train.text, dataset.train.AG)\n",
    "print('test: {}'.format(model.score(dataset.valid.text, dataset.valid.AG)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[model.vectorizer.id2word(id) for id in model.vectorizer.feature_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nlp516.model.MajorityBaseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dataset.train.text, dataset.train.AG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.precision_score(dataset.train.text, dataset.train.AG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.tree\n",
    "import sklearn.naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def subtask_dataset(dataset, task):\n",
    "    train = SimpleNamespace(x=dataset.train.text,\n",
    "                                y=getattr(dataset.train, task))\n",
    "    valid = SimpleNamespace(x=dataset.valid.text,\n",
    "                            y=getattr(dataset.valid, task))\n",
    "    return SimpleNamespace(train=train, valid=valid)\n",
    "\n",
    "def eval_metrics(model, dataset):\n",
    "    model.fit(dataset.train.x, dataset.train.y)\n",
    "    return {'accuracy': model.score(dataset.valid.x, dataset.valid.y),\n",
    "            'precision': model.precision_score(dataset.valid.x, dataset.valid.y),\n",
    "            'recall': model.recall_score(dataset.valid.x, dataset.valid.y),\n",
    "            'f1': model.f1_score(dataset.valid.x, dataset.valid.y)}\n",
    "\n",
    "def instantiate_models(classifiers, vectorizers):\n",
    "    models = {('MajorityBaseline', '-'): nlp516.model.MajorityBaseline()}\n",
    "    models.update(\n",
    "        {(c, v): nlp516.model.MlModel(classifier=classifiers[c](), \n",
    "                                      vectorizer=vectorizers[v]())\n",
    "         for c, v in itertools.product(classifiers.keys(), vectorizers.keys())\n",
    "        }\n",
    "    )\n",
    "    return models\n",
    "\n",
    "def eval_models(classifiers, vectorizers, task, dataset):\n",
    "    models = instantiate_models(classifiers, vectorizers)\n",
    "    results = {key: eval_metrics(model, dataset=subtask_dataset(dataset, task))\n",
    "               for key, model in models.items()}\n",
    "    return pd.DataFrame(results).transpose()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'AG'\n",
    "classifiers={'linear': lambda: sklearn.linear_model.LogisticRegression(),\n",
    "             'svm': lambda: sklearn.svm.SVC(gamma='scale'),\n",
    "             'tree': lambda: sklearn.tree.DecisionTreeClassifier(),\n",
    "             'bayes': lambda: sklearn.naive_bayes.GaussianNB()}\n",
    "vectorizers = {'frequency': lambda: nlp516.vectorizer.Unigram(100),\n",
    "               'presence': lambda: nlp516.vectorizer.UnigramPresence(100)}\n",
    "\n",
    "results = eval_models(classifiers=classifiers, vectorizers=vectorizers,\n",
    "                      task=task, dataset=dataset)\n",
    "print(language, task)\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = {'presence': lambda: nlp516.vectorizer.UnigramPresence(100)}\n",
    "results = eval_models(classifiers=classifiers, vectorizers=vectorizers,\n",
    "                      task='TR', dataset=dataset)\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
